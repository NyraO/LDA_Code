{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b2a3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@@@@ This is HornMorpho, version 4.0.5 @@@@\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb9d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/Kois/LDA/36Tokenizedsentences.csv')\n",
    "df=df.drop(['Unnamed: 0'], axis = 1)\n",
    "df=df.to_numpy().tolist()\n",
    "\n",
    "new_list=[]\n",
    "temp_list=[]\n",
    "for x in df:\n",
    "    for item in x:\n",
    "        if str(item) != 'nan':\n",
    "            temp_list.append(item)\n",
    "    new_list.append(temp_list)\n",
    "    temp_list=[]\n",
    "df=new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54285a0b",
   "metadata": {},
   "source": [
    "listOfNouns=[]\n",
    "def nounDoc(l):\n",
    "    Nouns=[]\n",
    "    for x in l:\n",
    "        y=hm.anal('amh',x,um=True)\n",
    "        try:\n",
    "            if y[1]['POS']=='n':\n",
    "                Nouns.append(x)\n",
    "        except:\n",
    "            if y==[]:\n",
    "                print()\n",
    "            elif y[0]['POS']=='n':\n",
    "               # print(x)\n",
    "                Nouns.append(x)\n",
    "    return Nouns\n",
    "\n",
    "for item in df:\n",
    "    listOfNouns.append(nounDoc(item))\n",
    " \n",
    "listOfNouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6aacc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FSTs for አማርኛ (analysis/generation) ...\n"
     ]
    }
   ],
   "source": [
    "def getVerbs(l):\n",
    "    verbs=[]\n",
    "    for x in l:\n",
    "        for item in x:\n",
    "            if item not in verbs:\n",
    "                try:\n",
    "                    y=hm.anal('amh',item,um=True)\n",
    "                    if y[0]['POS']=='v':\n",
    "                        verbs.append(item)\n",
    "                        f=open(\"verbs_corpus_36.txt\",\"a\",encoding=\"utf-8\")\n",
    "                        f.write((str(item)+\",\"))\n",
    "                        f.close()\n",
    "                    elif y==[]:\n",
    "                        print()\n",
    "                except:\n",
    "                    continue\n",
    "    return verbs\n",
    "\n",
    "verbs=getVerbs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b6e2294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ጠራ',\n",
       " 'ተናገረ',\n",
       " 'አነበበ',\n",
       " 'ገመተ',\n",
       " 'ፈላ',\n",
       " 'ኖረ',\n",
       " 'ሰከረ',\n",
       " 'መጣ',\n",
       " 'ሲያቃጥልብህ',\n",
       " 'መልሰህ',\n",
       " 'አለቀለቀ',\n",
       " 'ፈለገ',\n",
       " 'ታገለ',\n",
       " 'አጎነበሰ',\n",
       " 'ቻለ',\n",
       " 'ተጠቀመ',\n",
       " 'አረገ',\n",
       " 'አበረከተ',\n",
       " 'ተረባረበ',\n",
       " 'አወራ',\n",
       " 'አዋለ',\n",
       " 'ጠፋ',\n",
       " 'ቀጠለ',\n",
       " 'ተፈጸመ',\n",
       " 'እስክል',\n",
       " 'ጨረሰ',\n",
       " 'ተሳካ',\n",
       " 'ጠበቀ',\n",
       " 'ፈታ',\n",
       " 'አብሮ',\n",
       " 'ቆመ',\n",
       " 'አርጋ',\n",
       " 'ተጫወተ',\n",
       " 'ደከመ',\n",
       " 'ሰራ',\n",
       " 'አደነቀ',\n",
       " 'አጠቃ',\n",
       " 'ተለየ',\n",
       " 'ይቅር',\n",
       " 'ተማረ',\n",
       " 'ገደለ',\n",
       " 'ተፈጠረ',\n",
       " 'ወለደ',\n",
       " 'ታፈነ',\n",
       " 'ተመለከተ',\n",
       " 'ወከለ',\n",
       " 'አማተበ',\n",
       " 'ተከላከለ',\n",
       " 'ረገመ',\n",
       " 'ረካ',\n",
       " 'ፈጸመ',\n",
       " 'አቃጠለ',\n",
       " 'አወገዘ',\n",
       " 'አቀረበ',\n",
       " 'ታወረ',\n",
       " 'ጀመረ',\n",
       " 'ተሻገረ',\n",
       " 'አየ',\n",
       " 'አሸነፈ',\n",
       " 'ተፈታ',\n",
       " 'ፈጽሞ',\n",
       " 'ደገመ',\n",
       " 'ፈረመ',\n",
       " 'ተቃወመ',\n",
       " 'ተጋ',\n",
       " 'ያዘ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ac5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_verb=[]\n",
    "verb_set=set(verbs)\n",
    "\n",
    "for item in df:\n",
    "    item_set=set(item)\n",
    "    no_verb.append(list(item_set.difference(verb_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c9f1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_doc=no_verb\n",
    "#clean_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d4a5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 27 clusters with 8 clusters populated\n",
      "In stage 1: transferred 27 clusters with 7 clusters populated\n",
      "In stage 2: transferred 28 clusters with 9 clusters populated\n",
      "In stage 3: transferred 30 clusters with 8 clusters populated\n",
      "In stage 4: transferred 24 clusters with 6 clusters populated\n",
      "In stage 5: transferred 32 clusters with 7 clusters populated\n",
      "In stage 6: transferred 30 clusters with 7 clusters populated\n",
      "In stage 7: transferred 27 clusters with 8 clusters populated\n",
      "In stage 8: transferred 26 clusters with 7 clusters populated\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gsdmm import MovieGroupProcess\n",
    "\n",
    "# cast tweets to numpy array\n",
    "docs = clean_doc\n",
    "#docs = processed_lemma\n",
    "# create dictionary of all words in all documents\n",
    "# initialize a Dictionary\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "\n",
    "# filter extreme cases out of dictionary\n",
    "#dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "# create variable containing length of dictionary/vocab\n",
    "vocab_length = len(dictionary)\n",
    "\n",
    "# create BOW dictionary\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# initialize GSDMM\n",
    "gsdmm = MovieGroupProcess(K=10, alpha=0.3, beta=0.9, n_iters=9)\n",
    "\n",
    "# fit GSDMM model\n",
    "y = gsdmm.fit(docs, vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3fe6c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [ 4  5  1  0  0  4  7  4 11  0]\n",
      "Most important clusters (by number of docs inside): [8 6 1 7 5 0 2 9 4 3]\n",
      "\n",
      "Cluster 8 : [('አሜን', 2), ('ደረሰ', 2), ('ሙስሊም', 2)]\n",
      "\n",
      "Cluster 6 : [('መንግስት', 2), ('ተማሪ', 2), ('ታገተ', 2)]\n",
      "\n",
      "Cluster 1 : [('ጨርሰ', 1), ('ህዋህት', 1), ('መከራ', 1)]\n",
      "\n",
      "Cluster 7 : [('ብዙ', 1), ('አሸናፊ', 1), ('ቀንድ', 1)]\n",
      "\n",
      "Cluster 5 : [('አብይ', 2), ('ሀገር', 1), ('ድርግ', 1)]\n",
      "\n",
      "Cluster 0 : [('ፓርቲ', 2), ('ብልጽግና', 2), ('ጠላ', 2)]\n",
      "\n",
      "Cluster 2 : [('ጥግ', 1), ('ራስ', 1), ('ሰማ', 1)]\n",
      "\n",
      "Cluster 9 : []\n",
      "\n",
      "Cluster 4 : []\n",
      "\n",
      "Cluster 3 : []\n"
     ]
    }
   ],
   "source": [
    "word_cluster=[]\n",
    "cluster_index=[]\n",
    "# print number of documents per topic\n",
    "doc_count = np.array(gsdmm.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "\n",
    "# Topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-15:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "\n",
    "# define function to get top words per topic\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts = sorted(cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        word_cluster.append(sort_dicts)\n",
    "        cluster_index.append(cluster)\n",
    "        print(\"\\nCluster %s : %s\"%(cluster, sort_dicts))\n",
    "\n",
    "# get top words in topics\n",
    "top_words(gsdmm.cluster_word_distribution, top_index, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a782dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5016052128227412\n"
     ]
    }
   ],
   "source": [
    "# import library from gensim  \n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# define function to get words in topics\n",
    "def get_topics_lists(model, top_clusters, n_words):\n",
    "    '''\n",
    "    Gets lists of words in topics as a list of lists.\n",
    "    \n",
    "    model: gsdmm instance\n",
    "    top_clusters:  numpy array containing indices of top_clusters\n",
    "    n_words: top n number of words to include\n",
    "    \n",
    "    '''\n",
    "    # create empty list to contain topics\n",
    "    topics = []\n",
    "    \n",
    "    # iterate over top n clusters\n",
    "    for cluster in top_clusters:\n",
    "        #create sorted dictionary of word distributions\n",
    "        sorted_dict = sorted(model.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:n_words]\n",
    "        if len(sorted_dict)!=0:\n",
    "            #create empty list to contain words\n",
    "            topic = []\n",
    "\n",
    "            #iterate over top n words in topic\n",
    "            for k,v in sorted_dict:\n",
    "                #append words to topic list\n",
    "                topic.append(k)\n",
    "\n",
    "            #append topics to topics list    \n",
    "            topics.append(topic)\n",
    "    \n",
    "    return topics\n",
    "\n",
    "# get topics to feed to coherence model\n",
    "topics = get_topics_lists(gsdmm, top_index, 50) \n",
    "\n",
    "# evaluate model using Topic Coherence score\n",
    "cm_gsdmm = CoherenceModel(topics=topics, \n",
    "                          model=gsdmm,\n",
    "                          dictionary=dictionary, \n",
    "                          corpus=bow_corpus, \n",
    "                          texts=docs, \n",
    "                          coherence='c_v')\n",
    "\n",
    "# get coherence value\n",
    "coherence_gsdmm = cm_gsdmm.get_coherence()  \n",
    "\n",
    "print(coherence_gsdmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d33dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVerbs(l):\n",
    "    verbs=[]\n",
    "    for x in l:\n",
    "        for item in x:\n",
    "            try:\n",
    "                y=hm.anal('amh',item,um=True)\n",
    "                if y[0]['POS']=='v':\n",
    "                    verbs.append(item)\n",
    "                    f=open(\"verbs_corpus.txt\",\"a\",encoding=\"utf-8\")\n",
    "                    f.write((str(item)+\",\"))\n",
    "                    f.close()\n",
    "                elif y==[]:\n",
    "                    print()\n",
    "            except:\n",
    "                continue\n",
    "    return verbs\n",
    "\n",
    "k=getVerbs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e96d2",
   "metadata": {},
   "source": [
    "\n",
    "for item in k:\n",
    "    f=open(\"verbs_corpus.txt\",\"a\",encoding=\"utf-8\")\n",
    "    f.write((str(item)+\",\"))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a462b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
